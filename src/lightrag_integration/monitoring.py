"""
Monitoring and Alerting System

This module provides comprehensive system health monitoring, metrics collection,
performance monitoring, and alerting capabilities for the LightRAG integration.

Implements requirements 7.5 and 5.5 for system monitoring and performance tracking.
"""

import asyncio
import time
import psutil
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable, Union
from dataclasses import dataclass, field
from enum import Enum
from collections import deque, defaultdict
import json
import logging
from pathlib import Path

from .utils.logging import setup_logger
from .utils.health import HealthStatus, ComponentHealth, SystemHealth


class AlertSeverity(Enum):
    """Alert severity levels."""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


class MetricType(Enum):
    """Types of metrics that can be collected."""
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    TIMER = "timer"


@dataclass
class MetricValue:
    """A single metric measurement."""
    name: str
    value: Union[int, float]
    metric_type: MetricType
    timestamp: datetime = field(default_factory=datetime.now)
    tags: Dict[str, str] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class Alert:
    """An alert generated by the monitoring system."""
    alert_id: str
    severity: AlertSeverity
    title: str
    message: str
    component: str
    metric_name: Optional[str] = None
    metric_value: Optional[Union[int, float]] = None
    threshold: Optional[Union[int, float]] = None
    timestamp: datetime = field(default_factory=datetime.now)
    resolved: bool = False
    resolution_timestamp: Optional[datetime] = None
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class PerformanceMetrics:
    """Performance metrics for a specific operation."""
    operation_name: str
    total_calls: int = 0
    successful_calls: int = 0
    failed_calls: int = 0
    total_duration: float = 0.0
    min_duration: float = float('inf')
    max_duration: float = 0.0
    avg_duration: float = 0.0
    p95_duration: float = 0.0
    p99_duration: float = 0.0
    recent_durations: deque = field(default_factory=lambda: deque(maxlen=1000))
    last_updated: datetime = field(default_factory=datetime.now)


@dataclass
class SystemMetrics:
    """System-level metrics."""
    cpu_usage_percent: float = 0.0
    memory_usage_percent: float = 0.0
    memory_usage_mb: float = 0.0
    disk_usage_percent: float = 0.0
    disk_free_gb: float = 0.0
    active_threads: int = 0
    open_files: int = 0
    network_connections: int = 0
    timestamp: datetime = field(default_factory=datetime.now)


class MetricsCollector:
    """
    Collects and stores various types of metrics.
    
    This class provides functionality to collect counters, gauges, histograms,
    and timing metrics with support for tags and metadata.
    """
    
    def __init__(self, max_metrics_history: int = 10000):
        """Initialize the metrics collector."""
        self.max_metrics_history = max_metrics_history
        self.metrics_history: deque = deque(maxlen=max_metrics_history)
        self.current_metrics: Dict[str, MetricValue] = {}
        self.performance_metrics: Dict[str, PerformanceMetrics] = {}
        self.system_metrics_history: deque = deque(maxlen=1000)
        self.logger = setup_logger("metrics_collector")
        
        # Thread safety
        self._lock = threading.Lock()
        
        self.logger.info("Metrics collector initialized")
    
    def increment_counter(self, name: str, value: int = 1, tags: Dict[str, str] = None) -> None:
        """Increment a counter metric."""
        with self._lock:
            tags = tags or {}
            
            # Get existing counter or create new one
            existing = self.current_metrics.get(name)
            if existing and existing.metric_type == MetricType.COUNTER:
                new_value = existing.value + value
            else:
                new_value = value
            
            metric = MetricValue(
                name=name,
                value=new_value,
                metric_type=MetricType.COUNTER,
                tags=tags
            )
            
            self.current_metrics[name] = metric
            self.metrics_history.append(metric)
            
            self.logger.debug(f"Counter {name} incremented to {new_value}")
    
    def set_gauge(self, name: str, value: Union[int, float], tags: Dict[str, str] = None) -> None:
        """Set a gauge metric value."""
        with self._lock:
            tags = tags or {}
            
            metric = MetricValue(
                name=name,
                value=value,
                metric_type=MetricType.GAUGE,
                tags=tags
            )
            
            self.current_metrics[name] = metric
            self.metrics_history.append(metric)
            
            self.logger.debug(f"Gauge {name} set to {value}")
    
    def record_histogram(self, name: str, value: Union[int, float], tags: Dict[str, str] = None) -> None:
        """Record a value in a histogram metric."""
        with self._lock:
            tags = tags or {}
            
            metric = MetricValue(
                name=name,
                value=value,
                metric_type=MetricType.HISTOGRAM,
                tags=tags
            )
            
            self.metrics_history.append(metric)
            
            self.logger.debug(f"Histogram {name} recorded value {value}")
    
    def record_timing(self, operation_name: str, duration: float, success: bool = True) -> None:
        """Record timing information for an operation."""
        with self._lock:
            if operation_name not in self.performance_metrics:
                self.performance_metrics[operation_name] = PerformanceMetrics(operation_name)
            
            perf_metrics = self.performance_metrics[operation_name]
            
            # Update counters
            perf_metrics.total_calls += 1
            if success:
                perf_metrics.successful_calls += 1
            else:
                perf_metrics.failed_calls += 1
            
            # Update timing statistics
            perf_metrics.total_duration += duration
            perf_metrics.min_duration = min(perf_metrics.min_duration, duration)
            perf_metrics.max_duration = max(perf_metrics.max_duration, duration)
            perf_metrics.avg_duration = perf_metrics.total_duration / perf_metrics.total_calls
            
            # Add to recent durations for percentile calculations
            perf_metrics.recent_durations.append(duration)
            
            # Calculate percentiles
            if len(perf_metrics.recent_durations) > 0:
                sorted_durations = sorted(perf_metrics.recent_durations)
                p95_index = int(0.95 * len(sorted_durations))
                p99_index = int(0.99 * len(sorted_durations))
                
                perf_metrics.p95_duration = sorted_durations[min(p95_index, len(sorted_durations) - 1)]
                perf_metrics.p99_duration = sorted_durations[min(p99_index, len(sorted_durations) - 1)]
            
            perf_metrics.last_updated = datetime.now()
            
            # Also record as a timing metric
            metric = MetricValue(
                name=f"{operation_name}_duration",
                value=duration,
                metric_type=MetricType.TIMER,
                tags={"operation": operation_name, "success": str(success)}
            )
            self.metrics_history.append(metric)
            
            self.logger.debug(f"Recorded timing for {operation_name}: {duration:.3f}s (success: {success})")
    
    def collect_system_metrics(self) -> SystemMetrics:
        """Collect current system metrics."""
        try:
            # CPU usage
            cpu_percent = psutil.cpu_percent(interval=0.1)
            
            # Memory usage
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            memory_mb = memory.used / (1024 * 1024)
            
            # Disk usage
            disk = psutil.disk_usage('/')
            disk_percent = (disk.used / disk.total) * 100
            disk_free_gb = disk.free / (1024 * 1024 * 1024)
            
            # Process information
            process = psutil.Process()
            active_threads = process.num_threads()
            open_files = len(process.open_files())
            try:
                network_connections = len(process.net_connections())
            except (AttributeError, psutil.AccessDenied):
                # Fallback to connections() if net_connections() is not available or access denied
                try:
                    network_connections = len(process.connections())
                except (AttributeError, psutil.AccessDenied):
                    network_connections = 0
            
            system_metrics = SystemMetrics(
                cpu_usage_percent=cpu_percent,
                memory_usage_percent=memory_percent,
                memory_usage_mb=memory_mb,
                disk_usage_percent=disk_percent,
                disk_free_gb=disk_free_gb,
                active_threads=active_threads,
                open_files=open_files,
                network_connections=network_connections
            )
            
            with self._lock:
                self.system_metrics_history.append(system_metrics)
            
            return system_metrics
            
        except Exception as e:
            self.logger.error(f"Error collecting system metrics: {str(e)}")
            return SystemMetrics()  # Return empty metrics on error
    
    def get_current_metrics(self) -> Dict[str, MetricValue]:
        """Get current metric values."""
        with self._lock:
            return self.current_metrics.copy()
    
    def get_performance_metrics(self) -> Dict[str, PerformanceMetrics]:
        """Get performance metrics for all operations."""
        with self._lock:
            return self.performance_metrics.copy()
    
    def get_metrics_history(self, metric_name: Optional[str] = None, 
                          since: Optional[datetime] = None) -> List[MetricValue]:
        """Get metrics history, optionally filtered by name and time."""
        with self._lock:
            history = list(self.metrics_history)
        
        # Filter by metric name if specified
        if metric_name:
            history = [m for m in history if m.name == metric_name]
        
        # Filter by time if specified
        if since:
            history = [m for m in history if m.timestamp >= since]
        
        return history
    
    def get_system_metrics_history(self, since: Optional[datetime] = None) -> List[SystemMetrics]:
        """Get system metrics history."""
        with self._lock:
            history = list(self.system_metrics_history)
        
        if since:
            history = [m for m in history if m.timestamp >= since]
        
        return history
    
    def reset_metrics(self) -> None:
        """Reset all metrics (useful for testing)."""
        with self._lock:
            self.current_metrics.clear()
            self.performance_metrics.clear()
            self.metrics_history.clear()
            self.system_metrics_history.clear()
        
        self.logger.info("All metrics reset")


class AlertManager:
    """
    Manages alerts and notifications.
    
    This class handles alert generation, storage, and notification delivery
    based on configurable thresholds and conditions.
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """Initialize the alert manager."""
        self.config = config or {}
        self.logger = setup_logger("alert_manager")
        
        # Alert storage
        self.active_alerts: Dict[str, Alert] = {}
        self.alert_history: deque = deque(maxlen=self.config.get('max_alert_history', 1000))
        
        # Alert thresholds
        self.thresholds = self.config.get('thresholds', {})
        
        # Notification handlers
        self.notification_handlers: List[Callable[[Alert], None]] = []
        
        # Thread safety
        self._lock = threading.Lock()
        
        self.logger.info("Alert manager initialized")
    
    def add_notification_handler(self, handler: Callable[[Alert], None]) -> None:
        """Add a notification handler for alerts."""
        self.notification_handlers.append(handler)
        self.logger.info(f"Added notification handler: {handler.__name__}")
    
    def create_alert(self, severity: AlertSeverity, title: str, message: str, 
                    component: str, metric_name: Optional[str] = None,
                    metric_value: Optional[Union[int, float]] = None,
                    threshold: Optional[Union[int, float]] = None,
                    metadata: Dict[str, Any] = None) -> Alert:
        """Create a new alert."""
        alert_id = f"{component}_{metric_name or 'general'}_{int(time.time())}"
        
        alert = Alert(
            alert_id=alert_id,
            severity=severity,
            title=title,
            message=message,
            component=component,
            metric_name=metric_name,
            metric_value=metric_value,
            threshold=threshold,
            metadata=metadata or {}
        )
        
        with self._lock:
            self.active_alerts[alert_id] = alert
            self.alert_history.append(alert)
        
        # Send notifications
        self._send_notifications(alert)
        
        self.logger.warning(f"Alert created: {alert.title} ({alert.severity.value})")
        return alert
    
    def resolve_alert(self, alert_id: str, resolution_message: Optional[str] = None) -> bool:
        """Resolve an active alert."""
        with self._lock:
            if alert_id in self.active_alerts:
                alert = self.active_alerts[alert_id]
                alert.resolved = True
                alert.resolution_timestamp = datetime.now()
                
                if resolution_message:
                    alert.metadata['resolution_message'] = resolution_message
                
                del self.active_alerts[alert_id]
                
                self.logger.info(f"Alert resolved: {alert.title}")
                return True
        
        return False
    
    def check_metric_thresholds(self, metric: MetricValue) -> List[Alert]:
        """Check if a metric violates any configured thresholds."""
        alerts = []
        
        # Get thresholds for this metric
        metric_thresholds = self.thresholds.get(metric.name, {})
        
        for threshold_name, threshold_config in metric_thresholds.items():
            threshold_value = threshold_config.get('value')
            operator = threshold_config.get('operator', 'gt')  # gt, lt, eq, gte, lte
            severity = AlertSeverity(threshold_config.get('severity', 'warning'))
            
            if threshold_value is None:
                continue
            
            # Check threshold condition
            violation = False
            if operator == 'gt' and metric.value > threshold_value:
                violation = True
            elif operator == 'lt' and metric.value < threshold_value:
                violation = True
            elif operator == 'eq' and metric.value == threshold_value:
                violation = True
            elif operator == 'gte' and metric.value >= threshold_value:
                violation = True
            elif operator == 'lte' and metric.value <= threshold_value:
                violation = True
            
            if violation:
                alert = self.create_alert(
                    severity=severity,
                    title=f"Metric threshold violation: {metric.name}",
                    message=f"Metric {metric.name} value {metric.value} violates threshold {threshold_name} ({operator} {threshold_value})",
                    component="metrics",
                    metric_name=metric.name,
                    metric_value=metric.value,
                    threshold=threshold_value,
                    metadata={
                        'threshold_name': threshold_name,
                        'operator': operator,
                        'metric_tags': metric.tags
                    }
                )
                alerts.append(alert)
        
        return alerts
    
    def check_performance_thresholds(self, perf_metrics: PerformanceMetrics) -> List[Alert]:
        """Check if performance metrics violate any thresholds."""
        alerts = []
        
        # Check various performance thresholds
        checks = [
            ('avg_response_time', perf_metrics.avg_duration),
            ('p95_response_time', perf_metrics.p95_duration),
            ('p99_response_time', perf_metrics.p99_duration),
            ('error_rate', perf_metrics.failed_calls / max(perf_metrics.total_calls, 1))
        ]
        
        for check_name, value in checks:
            threshold_key = f"{perf_metrics.operation_name}_{check_name}"
            threshold_configs = self.thresholds.get(threshold_key, {})
            
            if not threshold_configs:
                continue
            
            # Iterate through all threshold configurations for this metric
            for threshold_name, threshold_config in threshold_configs.items():
                threshold_value = threshold_config.get('value')
                operator = threshold_config.get('operator', 'gt')
                
                if threshold_value is None:
                    continue
                
                # Check threshold condition
                violation = False
                if operator == 'gt' and value > threshold_value:
                    violation = True
                elif operator == 'lt' and value < threshold_value:
                    violation = True
                elif operator == 'eq' and value == threshold_value:
                    violation = True
                elif operator == 'gte' and value >= threshold_value:
                    violation = True
                elif operator == 'lte' and value <= threshold_value:
                    violation = True
                
                if violation:
                    severity = AlertSeverity(threshold_config.get('severity', 'warning'))
                    
                    alert = self.create_alert(
                        severity=severity,
                        title=f"Performance threshold violation: {perf_metrics.operation_name}",
                        message=f"Operation {perf_metrics.operation_name} {check_name} {value:.3f} violates threshold {threshold_name} ({operator} {threshold_value})",
                        component="performance",
                        metric_name=threshold_key,
                        metric_value=value,
                        threshold=threshold_value,
                        metadata={
                            'operation_name': perf_metrics.operation_name,
                            'check_type': check_name,
                            'threshold_name': threshold_name,
                            'operator': operator,
                            'total_calls': perf_metrics.total_calls,
                            'success_rate': perf_metrics.successful_calls / max(perf_metrics.total_calls, 1)
                        }
                    )
                    alerts.append(alert)
        
        return alerts
    
    def check_system_thresholds(self, system_metrics: SystemMetrics) -> List[Alert]:
        """Check if system metrics violate any thresholds."""
        alerts = []
        
        # System metric checks
        checks = [
            ('cpu_usage', system_metrics.cpu_usage_percent),
            ('memory_usage', system_metrics.memory_usage_percent),
            ('disk_usage', system_metrics.disk_usage_percent),
            ('active_threads', system_metrics.active_threads),
            ('open_files', system_metrics.open_files)
        ]
        
        for check_name, value in checks:
            threshold_configs = self.thresholds.get(f"system_{check_name}", {})
            
            if not threshold_configs:
                continue
            
            # Iterate through all threshold configurations for this metric
            for threshold_name, threshold_config in threshold_configs.items():
                threshold_value = threshold_config.get('value')
                if threshold_value is None:
                    continue
                
                operator = threshold_config.get('operator', 'gt')
                
                # Check threshold condition
                violation = False
                if operator == 'gt' and value > threshold_value:
                    violation = True
                elif operator == 'lt' and value < threshold_value:
                    violation = True
                elif operator == 'eq' and value == threshold_value:
                    violation = True
                elif operator == 'gte' and value >= threshold_value:
                    violation = True
                elif operator == 'lte' and value <= threshold_value:
                    violation = True
                
                if violation:
                    severity = AlertSeverity(threshold_config.get('severity', 'warning'))
                    
                    alert = self.create_alert(
                        severity=severity,
                        title=f"System threshold violation: {check_name}",
                        message=f"System {check_name} {value} violates threshold {threshold_name} ({operator} {threshold_value})",
                        component="system",
                        metric_name=f"system_{check_name}",
                        metric_value=value,
                        threshold=threshold_value,
                        metadata={
                            'system_metrics': system_metrics.__dict__, 
                            'threshold_name': threshold_name,
                            'operator': operator
                        }
                    )
                    alerts.append(alert)
        
        return alerts
    
    def get_active_alerts(self, severity: Optional[AlertSeverity] = None) -> List[Alert]:
        """Get active alerts, optionally filtered by severity."""
        with self._lock:
            alerts = list(self.active_alerts.values())
        
        if severity:
            alerts = [a for a in alerts if a.severity == severity]
        
        return sorted(alerts, key=lambda a: a.timestamp, reverse=True)
    
    def get_alert_history(self, since: Optional[datetime] = None, 
                         severity: Optional[AlertSeverity] = None) -> List[Alert]:
        """Get alert history, optionally filtered by time and severity."""
        with self._lock:
            history = list(self.alert_history)
        
        if since:
            history = [a for a in history if a.timestamp >= since]
        
        if severity:
            history = [a for a in history if a.severity == severity]
        
        return sorted(history, key=lambda a: a.timestamp, reverse=True)
    
    def get_alert_statistics(self) -> Dict[str, Any]:
        """Get alert statistics."""
        with self._lock:
            active_alerts = list(self.active_alerts.values())
            all_alerts = list(self.alert_history)
        
        # Count by severity
        severity_counts = defaultdict(int)
        for alert in all_alerts:
            severity_counts[alert.severity.value] += 1
        
        # Count by component
        component_counts = defaultdict(int)
        for alert in all_alerts:
            component_counts[alert.component] += 1
        
        # Recent alerts (last 24 hours)
        last_24h = datetime.now() - timedelta(hours=24)
        recent_alerts = [a for a in all_alerts if a.timestamp >= last_24h]
        
        return {
            'active_alerts': len(active_alerts),
            'total_alerts': len(all_alerts),
            'recent_alerts_24h': len(recent_alerts),
            'alerts_by_severity': dict(severity_counts),
            'alerts_by_component': dict(component_counts),
            'critical_alerts': len([a for a in active_alerts if a.severity == AlertSeverity.CRITICAL]),
            'error_alerts': len([a for a in active_alerts if a.severity == AlertSeverity.ERROR])
        }
    
    def _send_notifications(self, alert: Alert) -> None:
        """Send notifications for an alert."""
        for handler in self.notification_handlers:
            try:
                handler(alert)
            except Exception as e:
                self.logger.error(f"Error in notification handler {handler.__name__}: {str(e)}")


class PerformanceMonitor:
    """
    Performance monitoring system.
    
    This class provides comprehensive performance monitoring including
    response times, throughput, error rates, and system resource usage.
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """Initialize the performance monitor."""
        self.config = config or {}
        self.logger = setup_logger("performance_monitor")
        
        # Initialize components
        self.metrics_collector = MetricsCollector(
            max_metrics_history=self.config.get('max_metrics_history', 10000)
        )
        self.alert_manager = AlertManager(self.config.get('alerting', {}))
        
        # Monitoring state
        self.monitoring_active = False
        self.monitoring_interval = self.config.get('monitoring_interval', 30)  # seconds
        self.monitoring_task: Optional[asyncio.Task] = None
        
        # Performance tracking
        self.operation_timers: Dict[str, float] = {}
        
        self.logger.info("Performance monitor initialized")
    
    def start_monitoring(self) -> None:
        """Start the monitoring system."""
        if self.monitoring_active:
            self.logger.warning("Monitoring is already active")
            return
        
        self.monitoring_active = True
        self.monitoring_task = asyncio.create_task(self._monitoring_loop())
        self.logger.info("Performance monitoring started")
    
    async def stop_monitoring(self) -> None:
        """Stop the monitoring system."""
        if not self.monitoring_active:
            return
        
        self.monitoring_active = False
        
        if self.monitoring_task:
            self.monitoring_task.cancel()
            try:
                await self.monitoring_task
            except asyncio.CancelledError:
                pass
        
        self.logger.info("Performance monitoring stopped")
    
    def start_timer(self, operation_name: str) -> str:
        """Start timing an operation."""
        timer_id = f"{operation_name}_{int(time.time() * 1000000)}"
        self.operation_timers[timer_id] = time.time()
        return timer_id
    
    def end_timer(self, timer_id: str, operation_name: str, success: bool = True) -> float:
        """End timing an operation and record the duration."""
        if timer_id not in self.operation_timers:
            self.logger.warning(f"Timer {timer_id} not found")
            return 0.0
        
        start_time = self.operation_timers.pop(timer_id)
        duration = time.time() - start_time
        
        # Record the timing
        self.metrics_collector.record_timing(operation_name, duration, success)
        
        return duration
    
    def record_operation(self, operation_name: str, duration: float, success: bool = True) -> None:
        """Record an operation's performance metrics."""
        self.metrics_collector.record_timing(operation_name, duration, success)
        
        # Increment counters
        self.metrics_collector.increment_counter(f"{operation_name}_total")
        if success:
            self.metrics_collector.increment_counter(f"{operation_name}_success")
        else:
            self.metrics_collector.increment_counter(f"{operation_name}_error")
    
    def set_metric(self, name: str, value: Union[int, float], tags: Dict[str, str] = None) -> None:
        """Set a gauge metric value."""
        self.metrics_collector.set_gauge(name, value, tags)
    
    def increment_counter(self, name: str, value: int = 1, tags: Dict[str, str] = None) -> None:
        """Increment a counter metric."""
        self.metrics_collector.increment_counter(name, value, tags)
    
    def record_histogram(self, name: str, value: Union[int, float], tags: Dict[str, str] = None) -> None:
        """Record a histogram value."""
        self.metrics_collector.record_histogram(name, value, tags)
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """Get a comprehensive performance summary."""
        current_metrics = self.metrics_collector.get_current_metrics()
        performance_metrics = self.metrics_collector.get_performance_metrics()
        system_metrics = self.metrics_collector.collect_system_metrics()
        alert_stats = self.alert_manager.get_alert_statistics()
        
        # Calculate summary statistics
        total_operations = sum(pm.total_calls for pm in performance_metrics.values())
        total_errors = sum(pm.failed_calls for pm in performance_metrics.values())
        error_rate = (total_errors / max(total_operations, 1)) * 100
        
        # Get slowest operations
        slowest_operations = sorted(
            [(name, pm.avg_duration) for name, pm in performance_metrics.items()],
            key=lambda x: x[1],
            reverse=True
        )[:5]
        
        return {
            'timestamp': datetime.now().isoformat(),
            'system_metrics': {
                'cpu_usage_percent': system_metrics.cpu_usage_percent,
                'memory_usage_percent': system_metrics.memory_usage_percent,
                'memory_usage_mb': system_metrics.memory_usage_mb,
                'disk_usage_percent': system_metrics.disk_usage_percent,
                'active_threads': system_metrics.active_threads,
                'open_files': system_metrics.open_files
            },
            'performance_summary': {
                'total_operations': total_operations,
                'total_errors': total_errors,
                'error_rate_percent': error_rate,
                'operations_tracked': len(performance_metrics),
                'slowest_operations': slowest_operations
            },
            'alert_summary': alert_stats,
            'metrics_count': len(current_metrics)
        }
    
    def get_operation_metrics(self, operation_name: str) -> Optional[Dict[str, Any]]:
        """Get detailed metrics for a specific operation."""
        performance_metrics = self.metrics_collector.get_performance_metrics()
        
        if operation_name not in performance_metrics:
            return None
        
        pm = performance_metrics[operation_name]
        
        return {
            'operation_name': operation_name,
            'total_calls': pm.total_calls,
            'successful_calls': pm.successful_calls,
            'failed_calls': pm.failed_calls,
            'success_rate_percent': (pm.successful_calls / max(pm.total_calls, 1)) * 100,
            'error_rate_percent': (pm.failed_calls / max(pm.total_calls, 1)) * 100,
            'avg_duration_ms': pm.avg_duration * 1000,
            'min_duration_ms': pm.min_duration * 1000,
            'max_duration_ms': pm.max_duration * 1000,
            'p95_duration_ms': pm.p95_duration * 1000,
            'p99_duration_ms': pm.p99_duration * 1000,
            'last_updated': pm.last_updated.isoformat()
        }
    
    def export_metrics(self, format: str = 'json') -> str:
        """Export metrics in the specified format."""
        summary = self.get_performance_summary()
        
        if format.lower() == 'json':
            return json.dumps(summary, indent=2, default=str)
        else:
            raise ValueError(f"Unsupported export format: {format}")
    
    async def _monitoring_loop(self) -> None:
        """Main monitoring loop that runs periodically."""
        while self.monitoring_active:
            try:
                # Collect system metrics
                system_metrics = self.metrics_collector.collect_system_metrics()
                
                # Check for threshold violations
                alerts = []
                
                # Check system thresholds
                system_alerts = self.alert_manager.check_system_thresholds(system_metrics)
                alerts.extend(system_alerts)
                
                # Check performance thresholds
                performance_metrics = self.metrics_collector.get_performance_metrics()
                for perf_metrics in performance_metrics.values():
                    perf_alerts = self.alert_manager.check_performance_thresholds(perf_metrics)
                    alerts.extend(perf_alerts)
                
                # Check metric thresholds
                current_metrics = self.metrics_collector.get_current_metrics()
                for metric in current_metrics.values():
                    metric_alerts = self.alert_manager.check_metric_thresholds(metric)
                    alerts.extend(metric_alerts)
                
                if alerts:
                    self.logger.info(f"Generated {len(alerts)} alerts during monitoring cycle")
                
                # Wait for next monitoring cycle
                await asyncio.sleep(self.monitoring_interval)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error(f"Error in monitoring loop: {str(e)}")
                await asyncio.sleep(self.monitoring_interval)


# Convenience decorators and context managers

class timer:
    """Context manager for timing operations."""
    
    def __init__(self, performance_monitor: PerformanceMonitor, operation_name: str):
        self.performance_monitor = performance_monitor
        self.operation_name = operation_name
        self.timer_id = None
        self.success = True
    
    def __enter__(self):
        if hasattr(self.performance_monitor, 'start_timer'):
            self.timer_id = self.performance_monitor.start_timer(self.operation_name)
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            self.success = False
        
        if self.timer_id and hasattr(self.performance_monitor, 'end_timer'):
            self.performance_monitor.end_timer(self.timer_id, self.operation_name, self.success)


def monitor_performance(performance_monitor: PerformanceMonitor, operation_name: Optional[str] = None):
    """Decorator for monitoring function performance."""
    def decorator(func):
        nonlocal operation_name
        if operation_name is None:
            operation_name = f"{func.__module__}.{func.__name__}"
        
        if asyncio.iscoroutinefunction(func):
            async def async_wrapper(*args, **kwargs):
                with timer(performance_monitor, operation_name):
                    return await func(*args, **kwargs)
            return async_wrapper
        else:
            def sync_wrapper(*args, **kwargs):
                with timer(performance_monitor, operation_name):
                    return func(*args, **kwargs)
            return sync_wrapper
    
    return decorator


# Default notification handlers

def log_alert_handler(alert: Alert) -> None:
    """Default alert handler that logs alerts."""
    logger = logging.getLogger("alert_handler")
    
    log_level = {
        AlertSeverity.INFO: logger.info,
        AlertSeverity.WARNING: logger.warning,
        AlertSeverity.ERROR: logger.error,
        AlertSeverity.CRITICAL: logger.critical
    }.get(alert.severity, logger.info)
    
    log_level(f"ALERT [{alert.severity.value.upper()}] {alert.title}: {alert.message}")


def file_alert_handler(alert: Alert, alert_file: str = "alerts.log") -> None:
    """Alert handler that writes alerts to a file."""
    try:
        alert_data = {
            'timestamp': alert.timestamp.isoformat(),
            'alert_id': alert.alert_id,
            'severity': alert.severity.value,
            'title': alert.title,
            'message': alert.message,
            'component': alert.component,
            'metric_name': alert.metric_name,
            'metric_value': alert.metric_value,
            'threshold': alert.threshold,
            'metadata': alert.metadata
        }
        
        with open(alert_file, 'a') as f:
            f.write(json.dumps(alert_data) + '\n')
            
    except Exception as e:
        logger = logging.getLogger("alert_handler")
        logger.error(f"Failed to write alert to file {alert_file}: {str(e)}")


# Additional monitoring functionality for enhanced error handling integration

class EnhancedPerformanceMonitor(PerformanceMonitor):
    """
    Enhanced performance monitor with better error handling integration.
    
    This extends the base PerformanceMonitor with additional functionality
    for error tracking, health monitoring, and system diagnostics.
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """Initialize the enhanced performance monitor."""
        super().__init__(config)
        self._error_handler = None
        self._health_check_interval = self.config.get('health_check_interval', 60)
        self._last_health_check = None
        
        # Additional metrics for error tracking
        self._error_rate_threshold = self.config.get('error_rate_threshold', 5.0)  # 5% error rate
        self._response_time_threshold = self.config.get('response_time_threshold', 2.0)  # 2 seconds
        
        self.logger.info("Enhanced performance monitor initialized")
    
    def get_operation_metrics(self, operation_name: str) -> Optional[Dict[str, Any]]:
        """Get detailed metrics for a specific operation."""
        performance_metrics = self.metrics_collector.get_performance_metrics()
        
        if operation_name not in performance_metrics:
            return None
        
        pm = performance_metrics[operation_name]
        
        return {
            'operation_name': pm.operation_name,
            'total_calls': pm.total_calls,
            'successful_calls': pm.successful_calls,
            'failed_calls': pm.failed_calls,
            'success_rate_percent': round((pm.successful_calls / max(pm.total_calls, 1)) * 100, 2),
            'error_rate_percent': round((pm.failed_calls / max(pm.total_calls, 1)) * 100, 2),
            'avg_duration_ms': round(pm.avg_duration * 1000, 2),
            'min_duration_ms': round(pm.min_duration * 1000, 2),
            'max_duration_ms': round(pm.max_duration * 1000, 2),
            'p95_duration_ms': round(pm.p95_duration * 1000, 2),
            'p99_duration_ms': round(pm.p99_duration * 1000, 2),
            'last_updated': pm.last_updated.isoformat()
        }
    
    def export_metrics(self, format_type: str = "json") -> str:
        """Export metrics in the specified format."""
        if format_type.lower() != "json":
            raise ValueError(f"Unsupported export format: {format_type}")
        
        summary = self.get_performance_summary()
        return json.dumps(summary, indent=2)
    
    def get_health_status(self) -> Dict[str, Any]:
        """Get overall system health status."""
        system_metrics = self.metrics_collector.collect_system_metrics()
        active_alerts = self.alert_manager.get_active_alerts()
        critical_alerts = [a for a in active_alerts if a.severity == AlertSeverity.CRITICAL]
        error_alerts = [a for a in active_alerts if a.severity == AlertSeverity.ERROR]
        
        # Determine overall health
        if critical_alerts:
            health_status = "critical"
        elif error_alerts:
            health_status = "degraded"
        elif len(active_alerts) > 0:
            health_status = "warning"
        else:
            health_status = "healthy"
        
        return {
            'status': health_status,
            'timestamp': datetime.now().isoformat(),
            'system_metrics': {
                'cpu_usage_percent': system_metrics.cpu_usage_percent,
                'memory_usage_percent': system_metrics.memory_usage_percent,
                'disk_usage_percent': system_metrics.disk_usage_percent,
                'active_threads': system_metrics.active_threads
            },
            'alerts': {
                'total': len(active_alerts),
                'critical': len(critical_alerts),
                'error': len(error_alerts),
                'warning': len([a for a in active_alerts if a.severity == AlertSeverity.WARNING])
            },
            'monitoring_active': self.monitoring_active
        }
    
    def integrate_with_error_handler(self, error_handler) -> None:
        """Integrate monitoring with error handling system."""
        self._error_handler = error_handler
        
        # Add error handler metrics to monitoring
        def track_error_metrics():
            if not self._error_handler:
                return
                
            error_stats = self._error_handler.get_error_statistics()
            
            # Set gauges for error counts
            self.set_metric("errors_total", error_stats["total_errors"])
            self.set_metric("errors_recent_1h", error_stats["recent_errors_1h"])
            self.set_metric("errors_recent_24h", error_stats["recent_errors_24h"])
            
            # Set gauges for error categories
            for category, count in error_stats["errors_by_category"].items():
                self.set_metric(f"errors_by_category_{category}", count)
            
            # Set gauges for error severity
            for severity, count in error_stats["errors_by_severity"].items():
                self.set_metric(f"errors_by_severity_{severity}", count)
            
            # Create alerts for high error rates
            if error_stats["recent_errors_1h"] > 10:  # More than 10 errors in last hour
                self.alert_manager.create_alert(
                    severity=AlertSeverity.WARNING,
                    title="High Error Rate",
                    message=f"High error rate detected: {error_stats['recent_errors_1h']} errors in the last hour",
                    component="error_handler",
                    metric_name="errors_recent_1h",
                    metric_value=error_stats["recent_errors_1h"],
                    threshold=10
                )
            
            # Create alerts for circuit breakers
            if error_stats["circuit_breakers_open"] > 0:
                self.alert_manager.create_alert(
                    severity=AlertSeverity.ERROR,
                    title="Circuit Breakers Open",
                    message=f"{error_stats['circuit_breakers_open']} circuit breakers are currently open",
                    component="error_handler",
                    metric_name="circuit_breakers_open",
                    metric_value=error_stats["circuit_breakers_open"],
                    threshold=0
                )
        
        # Schedule periodic error metrics tracking
        self._error_metrics_tracker = track_error_metrics
        
        self.logger.info("Integrated monitoring with error handler")
    
    def check_operation_health(self, operation_name: str) -> Dict[str, Any]:
        """Check the health of a specific operation."""
        metrics = self.get_operation_metrics(operation_name)
        
        if not metrics:
            return {
                'operation_name': operation_name,
                'status': 'unknown',
                'message': 'No metrics available for this operation'
            }
        
        # Check error rate
        error_rate = metrics['error_rate_percent']
        avg_duration_ms = metrics['avg_duration_ms']
        
        issues = []
        status = 'healthy'
        
        if error_rate > self._error_rate_threshold:
            issues.append(f"High error rate: {error_rate}%")
            status = 'degraded'
        
        if avg_duration_ms > (self._response_time_threshold * 1000):
            issues.append(f"Slow response time: {avg_duration_ms}ms")
            if status == 'healthy':
                status = 'degraded'
        
        if metrics['total_calls'] == 0:
            issues.append("No recent activity")
            status = 'inactive'
        
        return {
            'operation_name': operation_name,
            'status': status,
            'error_rate_percent': error_rate,
            'avg_duration_ms': avg_duration_ms,
            'total_calls': metrics['total_calls'],
            'issues': issues,
            'message': '; '.join(issues) if issues else 'Operation is healthy'
        }
    
    def get_system_diagnostics(self) -> Dict[str, Any]:
        """Get comprehensive system diagnostics."""
        system_metrics = self.metrics_collector.collect_system_metrics()
        performance_metrics = self.metrics_collector.get_performance_metrics()
        active_alerts = self.alert_manager.get_active_alerts()
        
        # Analyze performance trends
        slow_operations = []
        error_prone_operations = []
        
        for name, pm in performance_metrics.items():
            if pm.avg_duration > self._response_time_threshold:
                slow_operations.append({
                    'operation': name,
                    'avg_duration_ms': round(pm.avg_duration * 1000, 2)
                })
            
            error_rate = (pm.failed_calls / max(pm.total_calls, 1)) * 100
            if error_rate > self._error_rate_threshold:
                error_prone_operations.append({
                    'operation': name,
                    'error_rate_percent': round(error_rate, 2),
                    'failed_calls': pm.failed_calls,
                    'total_calls': pm.total_calls
                })
        
        # System resource analysis
        resource_warnings = []
        if system_metrics.cpu_usage_percent > 80:
            resource_warnings.append(f"High CPU usage: {system_metrics.cpu_usage_percent}%")
        if system_metrics.memory_usage_percent > 85:
            resource_warnings.append(f"High memory usage: {system_metrics.memory_usage_percent}%")
        if system_metrics.disk_usage_percent > 90:
            resource_warnings.append(f"High disk usage: {system_metrics.disk_usage_percent}%")
        
        return {
            'timestamp': datetime.now().isoformat(),
            'system_health': {
                'cpu_usage_percent': system_metrics.cpu_usage_percent,
                'memory_usage_percent': system_metrics.memory_usage_percent,
                'disk_usage_percent': system_metrics.disk_usage_percent,
                'disk_free_gb': system_metrics.disk_free_gb,
                'active_threads': system_metrics.active_threads,
                'open_files': system_metrics.open_files,
                'resource_warnings': resource_warnings
            },
            'performance_analysis': {
                'total_operations': len(performance_metrics),
                'slow_operations': sorted(slow_operations, key=lambda x: x['avg_duration_ms'], reverse=True)[:5],
                'error_prone_operations': sorted(error_prone_operations, key=lambda x: x['error_rate_percent'], reverse=True)[:5]
            },
            'alerts': {
                'active_count': len(active_alerts),
                'critical_count': len([a for a in active_alerts if a.severity == AlertSeverity.CRITICAL]),
                'error_count': len([a for a in active_alerts if a.severity == AlertSeverity.ERROR]),
                'warning_count': len([a for a in active_alerts if a.severity == AlertSeverity.WARNING])
            },
            'error_handler_integration': {
                'integrated': self._error_handler is not None,
                'error_metrics_available': hasattr(self, '_error_metrics_tracker')
            }
        }
    
    async def run_health_check(self) -> Dict[str, Any]:
        """Run a comprehensive health check."""
        self.logger.info("Running comprehensive health check")
        
        try:
            # Collect current metrics
            system_metrics = self.metrics_collector.collect_system_metrics()
            performance_metrics = self.metrics_collector.get_performance_metrics()
            
            # Check each operation
            operation_health = {}
            for operation_name in performance_metrics.keys():
                operation_health[operation_name] = self.check_operation_health(operation_name)
            
            # Get system diagnostics
            diagnostics = self.get_system_diagnostics()
            
            # Determine overall health
            unhealthy_operations = [name for name, health in operation_health.items() 
                                  if health['status'] in ['degraded', 'critical']]
            
            if diagnostics['alerts']['critical_count'] > 0:
                overall_status = 'critical'
            elif diagnostics['alerts']['error_count'] > 0 or unhealthy_operations:
                overall_status = 'degraded'
            elif diagnostics['alerts']['warning_count'] > 0:
                overall_status = 'warning'
            else:
                overall_status = 'healthy'
            
            health_report = {
                'overall_status': overall_status,
                'timestamp': datetime.now().isoformat(),
                'system_diagnostics': diagnostics,
                'operation_health': operation_health,
                'recommendations': self._generate_health_recommendations(diagnostics, operation_health)
            }
            
            self._last_health_check = datetime.now()
            
            # Record health check metrics
            self.increment_counter("health_checks_completed")
            self.set_metric("last_health_check_timestamp", int(self._last_health_check.timestamp()))
            
            return health_report
            
        except Exception as e:
            self.logger.error(f"Health check failed: {str(e)}")
            self.increment_counter("health_checks_failed")
            
            return {
                'overall_status': 'unknown',
                'timestamp': datetime.now().isoformat(),
                'error': str(e),
                'recommendations': ['Check system logs for health check errors']
            }
    
    def _generate_health_recommendations(self, diagnostics: Dict[str, Any], 
                                       operation_health: Dict[str, Any]) -> List[str]:
        """Generate health recommendations based on diagnostics."""
        recommendations = []
        
        # System resource recommendations
        system_health = diagnostics['system_health']
        if system_health['cpu_usage_percent'] > 80:
            recommendations.append("Consider scaling CPU resources or optimizing high-CPU operations")
        
        if system_health['memory_usage_percent'] > 85:
            recommendations.append("Monitor memory usage and consider increasing available memory")
        
        if system_health['disk_usage_percent'] > 90:
            recommendations.append("Clean up disk space or increase storage capacity")
        
        if system_health['disk_free_gb'] < 1:
            recommendations.append("Critical: Very low disk space - immediate cleanup required")
        
        # Performance recommendations
        perf_analysis = diagnostics['performance_analysis']
        if perf_analysis['slow_operations']:
            slow_ops = [op['operation'] for op in perf_analysis['slow_operations'][:3]]
            recommendations.append(f"Optimize slow operations: {', '.join(slow_ops)}")
        
        if perf_analysis['error_prone_operations']:
            error_ops = [op['operation'] for op in perf_analysis['error_prone_operations'][:3]]
            recommendations.append(f"Investigate high error rates in: {', '.join(error_ops)}")
        
        # Alert recommendations
        alerts = diagnostics['alerts']
        if alerts['critical_count'] > 0:
            recommendations.append("Address critical alerts immediately")
        
        if alerts['error_count'] > 0:
            recommendations.append("Review and resolve error-level alerts")
        
        # Operation-specific recommendations
        degraded_ops = [name for name, health in operation_health.items() 
                       if health['status'] == 'degraded']
        if degraded_ops:
            recommendations.append(f"Monitor degraded operations: {', '.join(degraded_ops[:3])}")
        
        # Error handler integration recommendations
        if not diagnostics['error_handler_integration']['integrated']:
            recommendations.append("Consider integrating with error handler for better error tracking")
        
        return recommendations
    
    async def _monitoring_loop(self) -> None:
        """Enhanced monitoring loop with health checks."""
        self.logger.info("Starting enhanced monitoring loop")
        
        health_check_counter = 0
        health_check_interval_iterations = max(1, int(self._health_check_interval / self.monitoring_interval))
        
        try:
            while self.monitoring_active:
                try:
                    # Run standard monitoring
                    await super()._monitoring_loop_iteration()
                    
                    # Run periodic health checks
                    health_check_counter += 1
                    if health_check_counter >= health_check_interval_iterations:
                        health_report = await self.run_health_check()
                        self.logger.info(f"Health check completed - Status: {health_report['overall_status']}")
                        health_check_counter = 0
                    
                    # Track error metrics if integrated
                    if hasattr(self, '_error_metrics_tracker'):
                        try:
                            self._error_metrics_tracker()
                        except Exception as e:
                            self.logger.error(f"Error tracking error metrics: {str(e)}")
                    
                except Exception as e:
                    self.logger.error(f"Error in enhanced monitoring loop: {str(e)}")
                    self.increment_counter("monitoring_loop_errors")
                
                # Wait for next iteration
                await asyncio.sleep(self.monitoring_interval)
                
        except asyncio.CancelledError:
            self.logger.info("Enhanced monitoring loop cancelled")
            raise
        except Exception as e:
            self.logger.error(f"Enhanced monitoring loop failed: {str(e)}")
        finally:
            self.logger.info("Enhanced monitoring loop ended")
    
    async def _monitoring_loop_iteration(self) -> None:
        """Single iteration of the monitoring loop."""
        # Collect system metrics
        system_metrics = self.metrics_collector.collect_system_metrics()
        
        # Check system thresholds
        system_alerts = self.alert_manager.check_system_thresholds(system_metrics)
        if system_alerts:
            self.logger.info(f"Generated {len(system_alerts)} system alerts")
        
        # Check performance thresholds
        performance_metrics = self.metrics_collector.get_performance_metrics()
        for perf_metrics in performance_metrics.values():
            perf_alerts = self.alert_manager.check_performance_thresholds(perf_metrics)
            if perf_alerts:
                self.logger.info(f"Generated {len(perf_alerts)} performance alerts for {perf_metrics.operation_name}")
        
        # Check current metrics thresholds
        current_metrics = self.metrics_collector.get_current_metrics()
        for metric in current_metrics.values():
            metric_alerts = self.alert_manager.check_metric_thresholds(metric)
            if metric_alerts:
                self.logger.info(f"Generated {len(metric_alerts)} metric alerts for {metric.name}")
        
        # Update monitoring metrics
        self.increment_counter("monitoring_loop_iterations")


# Context managers and decorators for easier monitoring integration

class timer:
    """Context manager for timing operations."""
    
    def __init__(self, performance_monitor: PerformanceMonitor, operation_name: str):
        """Initialize the timer context manager."""
        self.performance_monitor = performance_monitor
        self.operation_name = operation_name
        self.start_time = None
        self.success = True
    
    def __enter__(self):
        """Start timing."""
        self.start_time = time.time()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """End timing and record metrics."""
        if self.start_time is not None:
            duration = time.time() - self.start_time
            success = exc_type is None and self.success
            self.performance_monitor.record_operation(self.operation_name, duration, success)
        
        # Don't suppress exceptions
        return False


def monitor_performance(performance_monitor: PerformanceMonitor, operation_name: str = None):
    """Decorator for monitoring function performance."""
    def decorator(func):
        nonlocal operation_name
        if operation_name is None:
            operation_name = f"{func.__module__}.{func.__name__}"
        
        if asyncio.iscoroutinefunction(func):
            @functools.wraps(func)
            async def async_wrapper(*args, **kwargs):
                start_time = time.time()
                success = True
                try:
                    result = await func(*args, **kwargs)
                    return result
                except Exception:
                    success = False
                    raise
                finally:
                    duration = time.time() - start_time
                    performance_monitor.record_operation(operation_name, duration, success)
            
            return async_wrapper
        else:
            @functools.wraps(func)
            def sync_wrapper(*args, **kwargs):
                start_time = time.time()
                success = True
                try:
                    result = func(*args, **kwargs)
                    return result
                except Exception:
                    success = False
                    raise
                finally:
                    duration = time.time() - start_time
                    performance_monitor.record_operation(operation_name, duration, success)
            
            return sync_wrapper
    
    return decorator


# Import functools for the decorator
import functools

# Alias for backward compatibility
class SystemMonitor:
    """Alias for EnhancedPerformanceMonitor for backward compatibility."""
    
    def __init__(self, config=None):
        self._monitor = EnhancedPerformanceMonitor()
    
    def __getattr__(self, name):
        return getattr(self._monitor, name)