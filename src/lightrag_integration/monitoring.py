"""
Monitoring and Alerting System

This module provides comprehensive system health monitoring, metrics collection,
performance monitoring, and alerting capabilities for the LightRAG integration.

Implements requirements 7.5 and 5.5 for system monitoring and performance tracking.
"""

import asyncio
import time
import psutil
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable, Union
from dataclasses import dataclass, field
from enum import Enum
from collections import deque, defaultdict
import json
import logging
from pathlib import Path

from .utils.logging import setup_logger
from .utils.health import HealthStatus, ComponentHealth, SystemHealth


class AlertSeverity(Enum):
    """Alert severity levels."""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


class MetricType(Enum):
    """Types of metrics that can be collected."""
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    TIMER = "timer"


@dataclass
class MetricValue:
    """A single metric measurement."""
    name: str
    value: Union[int, float]
    metric_type: MetricType
    timestamp: datetime = field(default_factory=datetime.now)
    tags: Dict[str, str] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class Alert:
    """An alert generated by the monitoring system."""
    alert_id: str
    severity: AlertSeverity
    title: str
    message: str
    component: str
    metric_name: Optional[str] = None
    metric_value: Optional[Union[int, float]] = None
    threshold: Optional[Union[int, float]] = None
    timestamp: datetime = field(default_factory=datetime.now)
    resolved: bool = False
    resolution_timestamp: Optional[datetime] = None
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class PerformanceMetrics:
    """Performance metrics for a specific operation."""
    operation_name: str
    total_calls: int = 0
    successful_calls: int = 0
    failed_calls: int = 0
    total_duration: float = 0.0
    min_duration: float = float('inf')
    max_duration: float = 0.0
    avg_duration: float = 0.0
    p95_duration: float = 0.0
    p99_duration: float = 0.0
    recent_durations: deque = field(default_factory=lambda: deque(maxlen=1000))
    last_updated: datetime = field(default_factory=datetime.now)


@dataclass
class SystemMetrics:
    """System-level metrics."""
    cpu_usage_percent: float = 0.0
    memory_usage_percent: float = 0.0
    memory_usage_mb: float = 0.0
    disk_usage_percent: float = 0.0
    disk_free_gb: float = 0.0
    active_threads: int = 0
    open_files: int = 0
    network_connections: int = 0
    timestamp: datetime = field(default_factory=datetime.now)


class MetricsCollector:
    """
    Collects and stores various types of metrics.
    
    This class provides functionality to collect counters, gauges, histograms,
    and timing metrics with support for tags and metadata.
    """
    
    def __init__(self, max_metrics_history: int = 10000):
        """Initialize the metrics collector."""
        self.max_metrics_history = max_metrics_history
        self.metrics_history: deque = deque(maxlen=max_metrics_history)
        self.current_metrics: Dict[str, MetricValue] = {}
        self.performance_metrics: Dict[str, PerformanceMetrics] = {}
        self.system_metrics_history: deque = deque(maxlen=1000)
        self.logger = setup_logger("metrics_collector")
        
        # Thread safety
        self._lock = threading.Lock()
        
        self.logger.info("Metrics collector initialized")
    
    def increment_counter(self, name: str, value: int = 1, tags: Dict[str, str] = None) -> None:
        """Increment a counter metric."""
        with self._lock:
            tags = tags or {}
            
            # Get existing counter or create new one
            existing = self.current_metrics.get(name)
            if existing and existing.metric_type == MetricType.COUNTER:
                new_value = existing.value + value
            else:
                new_value = value
            
            metric = MetricValue(
                name=name,
                value=new_value,
                metric_type=MetricType.COUNTER,
                tags=tags
            )
            
            self.current_metrics[name] = metric
            self.metrics_history.append(metric)
            
            self.logger.debug(f"Counter {name} incremented to {new_value}")
    
    def set_gauge(self, name: str, value: Union[int, float], tags: Dict[str, str] = None) -> None:
        """Set a gauge metric value."""
        with self._lock:
            tags = tags or {}
            
            metric = MetricValue(
                name=name,
                value=value,
                metric_type=MetricType.GAUGE,
                tags=tags
            )
            
            self.current_metrics[name] = metric
            self.metrics_history.append(metric)
            
            self.logger.debug(f"Gauge {name} set to {value}")
    
    def record_histogram(self, name: str, value: Union[int, float], tags: Dict[str, str] = None) -> None:
        """Record a value in a histogram metric."""
        with self._lock:
            tags = tags or {}
            
            metric = MetricValue(
                name=name,
                value=value,
                metric_type=MetricType.HISTOGRAM,
                tags=tags
            )
            
            self.metrics_history.append(metric)
            
            self.logger.debug(f"Histogram {name} recorded value {value}")
    
    def record_timing(self, operation_name: str, duration: float, success: bool = True) -> None:
        """Record timing information for an operation."""
        with self._lock:
            if operation_name not in self.performance_metrics:
                self.performance_metrics[operation_name] = PerformanceMetrics(operation_name)
            
            perf_metrics = self.performance_metrics[operation_name]
            
            # Update counters
            perf_metrics.total_calls += 1
            if success:
                perf_metrics.successful_calls += 1
            else:
                perf_metrics.failed_calls += 1
            
            # Update timing statistics
            perf_metrics.total_duration += duration
            perf_metrics.min_duration = min(perf_metrics.min_duration, duration)
            perf_metrics.max_duration = max(perf_metrics.max_duration, duration)
            perf_metrics.avg_duration = perf_metrics.total_duration / perf_metrics.total_calls
            
            # Add to recent durations for percentile calculations
            perf_metrics.recent_durations.append(duration)
            
            # Calculate percentiles
            if len(perf_metrics.recent_durations) > 0:
                sorted_durations = sorted(perf_metrics.recent_durations)
                p95_index = int(0.95 * len(sorted_durations))
                p99_index = int(0.99 * len(sorted_durations))
                
                perf_metrics.p95_duration = sorted_durations[min(p95_index, len(sorted_durations) - 1)]
                perf_metrics.p99_duration = sorted_durations[min(p99_index, len(sorted_durations) - 1)]
            
            perf_metrics.last_updated = datetime.now()
            
            # Also record as a timing metric
            metric = MetricValue(
                name=f"{operation_name}_duration",
                value=duration,
                metric_type=MetricType.TIMER,
                tags={"operation": operation_name, "success": str(success)}
            )
            self.metrics_history.append(metric)
            
            self.logger.debug(f"Recorded timing for {operation_name}: {duration:.3f}s (success: {success})")
    
    def collect_system_metrics(self) -> SystemMetrics:
        """Collect current system metrics."""
        try:
            # CPU usage
            cpu_percent = psutil.cpu_percent(interval=0.1)
            
            # Memory usage
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            memory_mb = memory.used / (1024 * 1024)
            
            # Disk usage
            disk = psutil.disk_usage('/')
            disk_percent = (disk.used / disk.total) * 100
            disk_free_gb = disk.free / (1024 * 1024 * 1024)
            
            # Process information
            process = psutil.Process()
            active_threads = process.num_threads()
            open_files = len(process.open_files())
            try:
                network_connections = len(process.net_connections())
            except (AttributeError, psutil.AccessDenied):
                # Fallback to connections() if net_connections() is not available or access denied
                try:
                    network_connections = len(process.connections())
                except (AttributeError, psutil.AccessDenied):
                    network_connections = 0
            
            system_metrics = SystemMetrics(
                cpu_usage_percent=cpu_percent,
                memory_usage_percent=memory_percent,
                memory_usage_mb=memory_mb,
                disk_usage_percent=disk_percent,
                disk_free_gb=disk_free_gb,
                active_threads=active_threads,
                open_files=open_files,
                network_connections=network_connections
            )
            
            with self._lock:
                self.system_metrics_history.append(system_metrics)
            
            return system_metrics
            
        except Exception as e:
            self.logger.error(f"Error collecting system metrics: {str(e)}")
            return SystemMetrics()  # Return empty metrics on error
    
    def get_current_metrics(self) -> Dict[str, MetricValue]:
        """Get current metric values."""
        with self._lock:
            return self.current_metrics.copy()
    
    def get_performance_metrics(self) -> Dict[str, PerformanceMetrics]:
        """Get performance metrics for all operations."""
        with self._lock:
            return self.performance_metrics.copy()
    
    def get_metrics_history(self, metric_name: Optional[str] = None, 
                          since: Optional[datetime] = None) -> List[MetricValue]:
        """Get metrics history, optionally filtered by name and time."""
        with self._lock:
            history = list(self.metrics_history)
        
        # Filter by metric name if specified
        if metric_name:
            history = [m for m in history if m.name == metric_name]
        
        # Filter by time if specified
        if since:
            history = [m for m in history if m.timestamp >= since]
        
        return history
    
    def get_system_metrics_history(self, since: Optional[datetime] = None) -> List[SystemMetrics]:
        """Get system metrics history."""
        with self._lock:
            history = list(self.system_metrics_history)
        
        if since:
            history = [m for m in history if m.timestamp >= since]
        
        return history
    
    def reset_metrics(self) -> None:
        """Reset all metrics (useful for testing)."""
        with self._lock:
            self.current_metrics.clear()
            self.performance_metrics.clear()
            self.metrics_history.clear()
            self.system_metrics_history.clear()
        
        self.logger.info("All metrics reset")


class AlertManager:
    """
    Manages alerts and notifications.
    
    This class handles alert generation, storage, and notification delivery
    based on configurable thresholds and conditions.
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """Initialize the alert manager."""
        self.config = config or {}
        self.logger = setup_logger("alert_manager")
        
        # Alert storage
        self.active_alerts: Dict[str, Alert] = {}
        self.alert_history: deque = deque(maxlen=self.config.get('max_alert_history', 1000))
        
        # Alert thresholds
        self.thresholds = self.config.get('thresholds', {})
        
        # Notification handlers
        self.notification_handlers: List[Callable[[Alert], None]] = []
        
        # Thread safety
        self._lock = threading.Lock()
        
        self.logger.info("Alert manager initialized")
    
    def add_notification_handler(self, handler: Callable[[Alert], None]) -> None:
        """Add a notification handler for alerts."""
        self.notification_handlers.append(handler)
        self.logger.info(f"Added notification handler: {handler.__name__}")
    
    def create_alert(self, severity: AlertSeverity, title: str, message: str, 
                    component: str, metric_name: Optional[str] = None,
                    metric_value: Optional[Union[int, float]] = None,
                    threshold: Optional[Union[int, float]] = None,
                    metadata: Dict[str, Any] = None) -> Alert:
        """Create a new alert."""
        alert_id = f"{component}_{metric_name or 'general'}_{int(time.time())}"
        
        alert = Alert(
            alert_id=alert_id,
            severity=severity,
            title=title,
            message=message,
            component=component,
            metric_name=metric_name,
            metric_value=metric_value,
            threshold=threshold,
            metadata=metadata or {}
        )
        
        with self._lock:
            self.active_alerts[alert_id] = alert
            self.alert_history.append(alert)
        
        # Send notifications
        self._send_notifications(alert)
        
        self.logger.warning(f"Alert created: {alert.title} ({alert.severity.value})")
        return alert
    
    def resolve_alert(self, alert_id: str, resolution_message: Optional[str] = None) -> bool:
        """Resolve an active alert."""
        with self._lock:
            if alert_id in self.active_alerts:
                alert = self.active_alerts[alert_id]
                alert.resolved = True
                alert.resolution_timestamp = datetime.now()
                
                if resolution_message:
                    alert.metadata['resolution_message'] = resolution_message
                
                del self.active_alerts[alert_id]
                
                self.logger.info(f"Alert resolved: {alert.title}")
                return True
        
        return False
    
    def check_metric_thresholds(self, metric: MetricValue) -> List[Alert]:
        """Check if a metric violates any configured thresholds."""
        alerts = []
        
        # Get thresholds for this metric
        metric_thresholds = self.thresholds.get(metric.name, {})
        
        for threshold_name, threshold_config in metric_thresholds.items():
            threshold_value = threshold_config.get('value')
            operator = threshold_config.get('operator', 'gt')  # gt, lt, eq, gte, lte
            severity = AlertSeverity(threshold_config.get('severity', 'warning'))
            
            if threshold_value is None:
                continue
            
            # Check threshold condition
            violation = False
            if operator == 'gt' and metric.value > threshold_value:
                violation = True
            elif operator == 'lt' and metric.value < threshold_value:
                violation = True
            elif operator == 'eq' and metric.value == threshold_value:
                violation = True
            elif operator == 'gte' and metric.value >= threshold_value:
                violation = True
            elif operator == 'lte' and metric.value <= threshold_value:
                violation = True
            
            if violation:
                alert = self.create_alert(
                    severity=severity,
                    title=f"Metric threshold violation: {metric.name}",
                    message=f"Metric {metric.name} value {metric.value} violates threshold {threshold_name} ({operator} {threshold_value})",
                    component="metrics",
                    metric_name=metric.name,
                    metric_value=metric.value,
                    threshold=threshold_value,
                    metadata={
                        'threshold_name': threshold_name,
                        'operator': operator,
                        'metric_tags': metric.tags
                    }
                )
                alerts.append(alert)
        
        return alerts
    
    def check_performance_thresholds(self, perf_metrics: PerformanceMetrics) -> List[Alert]:
        """Check if performance metrics violate any thresholds."""
        alerts = []
        
        # Check various performance thresholds
        checks = [
            ('avg_response_time', perf_metrics.avg_duration),
            ('p95_response_time', perf_metrics.p95_duration),
            ('p99_response_time', perf_metrics.p99_duration),
            ('error_rate', perf_metrics.failed_calls / max(perf_metrics.total_calls, 1))
        ]
        
        for check_name, value in checks:
            threshold_key = f"{perf_metrics.operation_name}_{check_name}"
            threshold_configs = self.thresholds.get(threshold_key, {})
            
            if not threshold_configs:
                continue
            
            # Iterate through all threshold configurations for this metric
            for threshold_name, threshold_config in threshold_configs.items():
                threshold_value = threshold_config.get('value')
                operator = threshold_config.get('operator', 'gt')
                
                if threshold_value is None:
                    continue
                
                # Check threshold condition
                violation = False
                if operator == 'gt' and value > threshold_value:
                    violation = True
                elif operator == 'lt' and value < threshold_value:
                    violation = True
                elif operator == 'eq' and value == threshold_value:
                    violation = True
                elif operator == 'gte' and value >= threshold_value:
                    violation = True
                elif operator == 'lte' and value <= threshold_value:
                    violation = True
                
                if violation:
                    severity = AlertSeverity(threshold_config.get('severity', 'warning'))
                    
                    alert = self.create_alert(
                        severity=severity,
                        title=f"Performance threshold violation: {perf_metrics.operation_name}",
                        message=f"Operation {perf_metrics.operation_name} {check_name} {value:.3f} violates threshold {threshold_name} ({operator} {threshold_value})",
                        component="performance",
                        metric_name=threshold_key,
                        metric_value=value,
                        threshold=threshold_value,
                        metadata={
                            'operation_name': perf_metrics.operation_name,
                            'check_type': check_name,
                            'threshold_name': threshold_name,
                            'operator': operator,
                            'total_calls': perf_metrics.total_calls,
                            'success_rate': perf_metrics.successful_calls / max(perf_metrics.total_calls, 1)
                        }
                    )
                    alerts.append(alert)
        
        return alerts
    
    def check_system_thresholds(self, system_metrics: SystemMetrics) -> List[Alert]:
        """Check if system metrics violate any thresholds."""
        alerts = []
        
        # System metric checks
        checks = [
            ('cpu_usage', system_metrics.cpu_usage_percent),
            ('memory_usage', system_metrics.memory_usage_percent),
            ('disk_usage', system_metrics.disk_usage_percent),
            ('active_threads', system_metrics.active_threads),
            ('open_files', system_metrics.open_files)
        ]
        
        for check_name, value in checks:
            threshold_configs = self.thresholds.get(f"system_{check_name}", {})
            
            if not threshold_configs:
                continue
            
            # Iterate through all threshold configurations for this metric
            for threshold_name, threshold_config in threshold_configs.items():
                threshold_value = threshold_config.get('value')
                if threshold_value is None:
                    continue
                
                operator = threshold_config.get('operator', 'gt')
                
                # Check threshold condition
                violation = False
                if operator == 'gt' and value > threshold_value:
                    violation = True
                elif operator == 'lt' and value < threshold_value:
                    violation = True
                elif operator == 'eq' and value == threshold_value:
                    violation = True
                elif operator == 'gte' and value >= threshold_value:
                    violation = True
                elif operator == 'lte' and value <= threshold_value:
                    violation = True
                
                if violation:
                    severity = AlertSeverity(threshold_config.get('severity', 'warning'))
                    
                    alert = self.create_alert(
                        severity=severity,
                        title=f"System threshold violation: {check_name}",
                        message=f"System {check_name} {value} violates threshold {threshold_name} ({operator} {threshold_value})",
                        component="system",
                        metric_name=f"system_{check_name}",
                        metric_value=value,
                        threshold=threshold_value,
                        metadata={
                            'system_metrics': system_metrics.__dict__, 
                            'threshold_name': threshold_name,
                            'operator': operator
                        }
                    )
                    alerts.append(alert)
        
        return alerts
    
    def get_active_alerts(self, severity: Optional[AlertSeverity] = None) -> List[Alert]:
        """Get active alerts, optionally filtered by severity."""
        with self._lock:
            alerts = list(self.active_alerts.values())
        
        if severity:
            alerts = [a for a in alerts if a.severity == severity]
        
        return sorted(alerts, key=lambda a: a.timestamp, reverse=True)
    
    def get_alert_history(self, since: Optional[datetime] = None, 
                         severity: Optional[AlertSeverity] = None) -> List[Alert]:
        """Get alert history, optionally filtered by time and severity."""
        with self._lock:
            history = list(self.alert_history)
        
        if since:
            history = [a for a in history if a.timestamp >= since]
        
        if severity:
            history = [a for a in history if a.severity == severity]
        
        return sorted(history, key=lambda a: a.timestamp, reverse=True)
    
    def get_alert_statistics(self) -> Dict[str, Any]:
        """Get alert statistics."""
        with self._lock:
            active_alerts = list(self.active_alerts.values())
            all_alerts = list(self.alert_history)
        
        # Count by severity
        severity_counts = defaultdict(int)
        for alert in all_alerts:
            severity_counts[alert.severity.value] += 1
        
        # Count by component
        component_counts = defaultdict(int)
        for alert in all_alerts:
            component_counts[alert.component] += 1
        
        # Recent alerts (last 24 hours)
        last_24h = datetime.now() - timedelta(hours=24)
        recent_alerts = [a for a in all_alerts if a.timestamp >= last_24h]
        
        return {
            'active_alerts': len(active_alerts),
            'total_alerts': len(all_alerts),
            'recent_alerts_24h': len(recent_alerts),
            'alerts_by_severity': dict(severity_counts),
            'alerts_by_component': dict(component_counts),
            'critical_alerts': len([a for a in active_alerts if a.severity == AlertSeverity.CRITICAL]),
            'error_alerts': len([a for a in active_alerts if a.severity == AlertSeverity.ERROR])
        }
    
    def _send_notifications(self, alert: Alert) -> None:
        """Send notifications for an alert."""
        for handler in self.notification_handlers:
            try:
                handler(alert)
            except Exception as e:
                self.logger.error(f"Error in notification handler {handler.__name__}: {str(e)}")


class PerformanceMonitor:
    """
    Performance monitoring system.
    
    This class provides comprehensive performance monitoring including
    response times, throughput, error rates, and system resource usage.
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """Initialize the performance monitor."""
        self.config = config or {}
        self.logger = setup_logger("performance_monitor")
        
        # Initialize components
        self.metrics_collector = MetricsCollector(
            max_metrics_history=self.config.get('max_metrics_history', 10000)
        )
        self.alert_manager = AlertManager(self.config.get('alerting', {}))
        
        # Monitoring state
        self.monitoring_active = False
        self.monitoring_interval = self.config.get('monitoring_interval', 30)  # seconds
        self.monitoring_task: Optional[asyncio.Task] = None
        
        # Performance tracking
        self.operation_timers: Dict[str, float] = {}
        
        self.logger.info("Performance monitor initialized")
    
    def start_monitoring(self) -> None:
        """Start the monitoring system."""
        if self.monitoring_active:
            self.logger.warning("Monitoring is already active")
            return
        
        self.monitoring_active = True
        self.monitoring_task = asyncio.create_task(self._monitoring_loop())
        self.logger.info("Performance monitoring started")
    
    async def stop_monitoring(self) -> None:
        """Stop the monitoring system."""
        if not self.monitoring_active:
            return
        
        self.monitoring_active = False
        
        if self.monitoring_task:
            self.monitoring_task.cancel()
            try:
                await self.monitoring_task
            except asyncio.CancelledError:
                pass
        
        self.logger.info("Performance monitoring stopped")
    
    def start_timer(self, operation_name: str) -> str:
        """Start timing an operation."""
        timer_id = f"{operation_name}_{int(time.time() * 1000000)}"
        self.operation_timers[timer_id] = time.time()
        return timer_id
    
    def end_timer(self, timer_id: str, operation_name: str, success: bool = True) -> float:
        """End timing an operation and record the duration."""
        if timer_id not in self.operation_timers:
            self.logger.warning(f"Timer {timer_id} not found")
            return 0.0
        
        start_time = self.operation_timers.pop(timer_id)
        duration = time.time() - start_time
        
        # Record the timing
        self.metrics_collector.record_timing(operation_name, duration, success)
        
        return duration
    
    def record_operation(self, operation_name: str, duration: float, success: bool = True) -> None:
        """Record an operation's performance metrics."""
        self.metrics_collector.record_timing(operation_name, duration, success)
        
        # Increment counters
        self.metrics_collector.increment_counter(f"{operation_name}_total")
        if success:
            self.metrics_collector.increment_counter(f"{operation_name}_success")
        else:
            self.metrics_collector.increment_counter(f"{operation_name}_error")
    
    def set_metric(self, name: str, value: Union[int, float], tags: Dict[str, str] = None) -> None:
        """Set a gauge metric value."""
        self.metrics_collector.set_gauge(name, value, tags)
    
    def increment_counter(self, name: str, value: int = 1, tags: Dict[str, str] = None) -> None:
        """Increment a counter metric."""
        self.metrics_collector.increment_counter(name, value, tags)
    
    def record_histogram(self, name: str, value: Union[int, float], tags: Dict[str, str] = None) -> None:
        """Record a histogram value."""
        self.metrics_collector.record_histogram(name, value, tags)
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """Get a comprehensive performance summary."""
        current_metrics = self.metrics_collector.get_current_metrics()
        performance_metrics = self.metrics_collector.get_performance_metrics()
        system_metrics = self.metrics_collector.collect_system_metrics()
        alert_stats = self.alert_manager.get_alert_statistics()
        
        # Calculate summary statistics
        total_operations = sum(pm.total_calls for pm in performance_metrics.values())
        total_errors = sum(pm.failed_calls for pm in performance_metrics.values())
        error_rate = (total_errors / max(total_operations, 1)) * 100
        
        # Get slowest operations
        slowest_operations = sorted(
            [(name, pm.avg_duration) for name, pm in performance_metrics.items()],
            key=lambda x: x[1],
            reverse=True
        )[:5]
        
        return {
            'timestamp': datetime.now().isoformat(),
            'system_metrics': {
                'cpu_usage_percent': system_metrics.cpu_usage_percent,
                'memory_usage_percent': system_metrics.memory_usage_percent,
                'memory_usage_mb': system_metrics.memory_usage_mb,
                'disk_usage_percent': system_metrics.disk_usage_percent,
                'active_threads': system_metrics.active_threads,
                'open_files': system_metrics.open_files
            },
            'performance_summary': {
                'total_operations': total_operations,
                'total_errors': total_errors,
                'error_rate_percent': error_rate,
                'operations_tracked': len(performance_metrics),
                'slowest_operations': slowest_operations
            },
            'alert_summary': alert_stats,
            'metrics_count': len(current_metrics)
        }
    
    def get_operation_metrics(self, operation_name: str) -> Optional[Dict[str, Any]]:
        """Get detailed metrics for a specific operation."""
        performance_metrics = self.metrics_collector.get_performance_metrics()
        
        if operation_name not in performance_metrics:
            return None
        
        pm = performance_metrics[operation_name]
        
        return {
            'operation_name': operation_name,
            'total_calls': pm.total_calls,
            'successful_calls': pm.successful_calls,
            'failed_calls': pm.failed_calls,
            'success_rate_percent': (pm.successful_calls / max(pm.total_calls, 1)) * 100,
            'error_rate_percent': (pm.failed_calls / max(pm.total_calls, 1)) * 100,
            'avg_duration_ms': pm.avg_duration * 1000,
            'min_duration_ms': pm.min_duration * 1000,
            'max_duration_ms': pm.max_duration * 1000,
            'p95_duration_ms': pm.p95_duration * 1000,
            'p99_duration_ms': pm.p99_duration * 1000,
            'last_updated': pm.last_updated.isoformat()
        }
    
    def export_metrics(self, format: str = 'json') -> str:
        """Export metrics in the specified format."""
        summary = self.get_performance_summary()
        
        if format.lower() == 'json':
            return json.dumps(summary, indent=2, default=str)
        else:
            raise ValueError(f"Unsupported export format: {format}")
    
    async def _monitoring_loop(self) -> None:
        """Main monitoring loop that runs periodically."""
        while self.monitoring_active:
            try:
                # Collect system metrics
                system_metrics = self.metrics_collector.collect_system_metrics()
                
                # Check for threshold violations
                alerts = []
                
                # Check system thresholds
                system_alerts = self.alert_manager.check_system_thresholds(system_metrics)
                alerts.extend(system_alerts)
                
                # Check performance thresholds
                performance_metrics = self.metrics_collector.get_performance_metrics()
                for perf_metrics in performance_metrics.values():
                    perf_alerts = self.alert_manager.check_performance_thresholds(perf_metrics)
                    alerts.extend(perf_alerts)
                
                # Check metric thresholds
                current_metrics = self.metrics_collector.get_current_metrics()
                for metric in current_metrics.values():
                    metric_alerts = self.alert_manager.check_metric_thresholds(metric)
                    alerts.extend(metric_alerts)
                
                if alerts:
                    self.logger.info(f"Generated {len(alerts)} alerts during monitoring cycle")
                
                # Wait for next monitoring cycle
                await asyncio.sleep(self.monitoring_interval)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error(f"Error in monitoring loop: {str(e)}")
                await asyncio.sleep(self.monitoring_interval)


# Convenience decorators and context managers

class timer:
    """Context manager for timing operations."""
    
    def __init__(self, performance_monitor: PerformanceMonitor, operation_name: str):
        self.performance_monitor = performance_monitor
        self.operation_name = operation_name
        self.timer_id = None
        self.success = True
    
    def __enter__(self):
        if hasattr(self.performance_monitor, 'start_timer'):
            self.timer_id = self.performance_monitor.start_timer(self.operation_name)
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            self.success = False
        
        if self.timer_id and hasattr(self.performance_monitor, 'end_timer'):
            self.performance_monitor.end_timer(self.timer_id, self.operation_name, self.success)


def monitor_performance(performance_monitor: PerformanceMonitor, operation_name: Optional[str] = None):
    """Decorator for monitoring function performance."""
    def decorator(func):
        nonlocal operation_name
        if operation_name is None:
            operation_name = f"{func.__module__}.{func.__name__}"
        
        if asyncio.iscoroutinefunction(func):
            async def async_wrapper(*args, **kwargs):
                with timer(performance_monitor, operation_name):
                    return await func(*args, **kwargs)
            return async_wrapper
        else:
            def sync_wrapper(*args, **kwargs):
                with timer(performance_monitor, operation_name):
                    return func(*args, **kwargs)
            return sync_wrapper
    
    return decorator


# Default notification handlers

def log_alert_handler(alert: Alert) -> None:
    """Default alert handler that logs alerts."""
    logger = logging.getLogger("alert_handler")
    
    log_level = {
        AlertSeverity.INFO: logger.info,
        AlertSeverity.WARNING: logger.warning,
        AlertSeverity.ERROR: logger.error,
        AlertSeverity.CRITICAL: logger.critical
    }.get(alert.severity, logger.info)
    
    log_level(f"ALERT [{alert.severity.value.upper()}] {alert.title}: {alert.message}")


def file_alert_handler(alert: Alert, alert_file: str = "alerts.log") -> None:
    """Alert handler that writes alerts to a file."""
    try:
        alert_data = {
            'timestamp': alert.timestamp.isoformat(),
            'alert_id': alert.alert_id,
            'severity': alert.severity.value,
            'title': alert.title,
            'message': alert.message,
            'component': alert.component,
            'metric_name': alert.metric_name,
            'metric_value': alert.metric_value,
            'threshold': alert.threshold,
            'metadata': alert.metadata
        }
        
        with open(alert_file, 'a') as f:
            f.write(json.dumps(alert_data) + '\n')
            
    except Exception as e:
        logger = logging.getLogger("alert_handler")
        logger.error(f"Failed to write alert to file {alert_file}: {str(e)}")